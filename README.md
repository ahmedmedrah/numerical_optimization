# numerical_optimization
 Implementation of various gradient descent algoritms

1- Batch gradient descent

2- Mini-batch gd

3- Stochastic gd

4- Momentum-based gd

5- NAG gd

6- Adagrad

7- RMSProp

8- Adam
